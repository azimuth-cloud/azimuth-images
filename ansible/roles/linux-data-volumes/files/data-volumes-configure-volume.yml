---

- name: Fail if volume ID is not in metadata
  fail:
    msg: "Metadata item '{{ data_volume.metadata_var }}' is not present."
  when: data_volume.metadata_var not in openstack_metadata

- name: Get volume ID for volume
  set_fact:
    data_volume_id: "{{ openstack_metadata[data_volume.metadata_var] }}"

- name: Get Azimuth user metadata
  set_fact:
    azimuth_username: "azimuth"
    azimuth_uid: "{{ openstack_metadata['azimuth_workstation_uid'] }}"
    azimuth_gid: "{{ openstack_metadata['azimuth_workstation_gid'] }}"
    azimuth_is_sudo: "{{ openstack_metadata['azimuth_workstation_is_sudo'] }}"
    azimuth_user_data: "{{ openstack_userdata }}"
  when: create_user | bool

# Use the same discovery logic as CSI Cinder, so that we succeed and fail on the same clouds
# https://github.com/kubernetes/cloud-provider-openstack/blob/34f5f980f523e191285c568a8a77a2ca683272be/pkg/util/mount/mount.go#L152

- name: Stat candidate device paths
  stat:
    path: "/dev/disk/by-id/{{ item }}"
  loop:
    # KVM
    - "{{ 'virtio-{}'.format(data_volume_id[:20]) }}"
    # KVM #852
    - "{{ 'virtio-{}'.format(data_volume_id) }}"
    # KVM virtio-scsi
    - "{{ 'scsi-0QEMU_QEMU_HARDDISK_{}'.format(data_volume_id[:20]) }}"
    # KVM virtio-scsi #852
    - "{{ 'scsi-0QEMU_QEMU_HARDDISK_{}'.format(data_volume_id) }}"
    # ESXi
    - "{{ 'wwn-0x{}'.format(data_volume_id | replace('-', '')) }}"
  register: candidate_device_paths_stat

- name: Set volume block device name
  set_fact:
    data_volume_device: >-
      {{-
        candidate_device_paths_stat.results |
          selectattr("stat.exists") |
          map(attribute = "stat.lnk_source") |
          first |
          default("") |
          trim("/") |
          split("/") |
          last
      }}

- name: Fail if block device was not found
  fail:
    msg: "Could not locate block device for volume {{ data_volume_id }}."
  when: data_volume_device == ""

- name: Create filesystem on device
  community.general.filesystem:
    fstype: "{{ data_volume.get('fs_type', 'ext4') }}"
    dev: "/dev/{{ data_volume_device }}"
  register: data_volume_fs

- name: Update ansible_devices to populate filesystem UUID
  setup:
    filter:
      - ansible_devices
  when: data_volume_fs is changed

- name: Mount up filesystem using UUID
  ansible.posix.mount:
    # Get the UUID from ansible_devices
    src: "UUID={{ ansible_devices[data_volume_device].links.uuids[0] }}"
    path: "{{ data_volume.mountpoint }}"
    state: mounted
    fstype: "{{ data_volume.get('fs_type', 'ext4') }}"
    opts: "{{ data_volume.get('opts', omit) }}"

- name: Ensure the Azimuth user is created
  ansible.builtin.user:
    name: "{{ azimuth_username }}"
    uid: "{{ azimuth_uid }}"
    gid: "{{ azimuth_gid }}"
    home: "{{ data_volume.mountpoint }}/{{ azimuth_username }}-home"
  when: create_user | bool

- name: Setup public key for the Azimuth user
  ansible.posix.authorized_key:
    user: "{{ azimuth_username }}"
    state: present
    key: "{{ item.ssh_authorized_keys[0] }}"
  with_items: "{{ azimuth_user_data }}"
  when: create_user | bool

- name: Add the Azimuth user to sudoers
  ansible.builtin.user:
    name: "{{ azimuth_username }}"
    groups: sudo
  when: 
    - create_user | bool
    - azimuth_is_sudo | bool

- name: Make sudo without password for users
  ansible.builtin.copy:
    dest: /etc/sudoers.d/80-ansible-sudo-user
    content: "{{ azimuth_username }} ALL=(ALL) NOPASSWD:ALL"
    mode: 0440
  when: 
    - create_user | bool
    - azimuth_is_sudo | bool

- name: Ensure mountpoint permissions
  ansible.builtin.file:
    state: directory
    owner: "{{ data_volume.owner }}"
    group: "{{ data_volume.group }}"
    path: "{{ data_volume.mountpoint }}"
    mode: "{{ data_volume.get('mode', '0755') }}"
